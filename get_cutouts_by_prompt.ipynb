{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pycocotools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torch torchvision torchaudio -f https://download.pytorch.org/whl/cu121/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests\n",
    "import base64\n",
    "import json\n",
    "\n",
    "input_image = \"./Images/00100sPORTRAIT_00100_BURST20230217194540475_COVER.jpg\"\n",
    "with open(input_image, \"rb\") as image_file:\n",
    "  encoded_image = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "url = \"https://apps.beam.cloud/oregk\"\n",
    "payload = {\"image\": encoded_image, \"prompt\": \"person\"}\n",
    "headers = {\n",
    "  \"Accept\": \"*/*\",\n",
    "  \"Accept-Encoding\": \"gzip, deflate\",\n",
    "  \"Authorization\": \"Basic NzU0NTA2YmNjYzE4ZjNiMjNiMTc3OTgwNTY3ODcyNzQ6MTc4NDc2MTNiYmUyNDc3OTZlMGZlYTY0ZTJkYzMzMDY=\",\n",
    "  \"Connection\": \"keep-alive\",\n",
    "  \"Content-Type\": \"application/json\",\n",
    "}\n",
    "\n",
    "response = requests.request(\"POST\", url, \n",
    "  headers=headers,\n",
    "  data=json.dumps(payload)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to connect to the remote Jupyter Server 'http://0.0.0.0:2326/'. Verify the server is running and reachable. (request to http://0.0.0.0:2326/notebook/hub/api failed, reason: connect ECONNREFUSED 0.0.0.0:2326)."
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import sys\n",
    "import os\n",
    "from imageai.Detection import ObjectDetection\n",
    "import torch\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "sys.path.append(\"..\")\n",
    "import pycocotools.mask as maskUtils\n",
    "import subprocess\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_mask(mask, ax, random_color=False):\n",
    "    if random_color:\n",
    "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
    "    else:\n",
    "        color = np.array([30/255, 144/255, 255/255, 0.6])\n",
    "    h, w = mask.shape[-2:]\n",
    "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "    ax.imshow(mask_image)\n",
    "    \n",
    "def show_points(coords, labels, ax, marker_size=375):\n",
    "    pos_points = coords[labels==1]\n",
    "    neg_points = coords[labels==0]\n",
    "    ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
    "    ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)   \n",
    "    \n",
    "def show_box(box, ax):\n",
    "    x0, y0 = box[0], box[1]\n",
    "    w, h = box[2] - box[0], box[3] - box[1]\n",
    "    ax.add_patch(plt.Rectangle((x0, y0), w, h, edgecolor='green', facecolor=(0,0,0,0), lw=2))  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Get a list of all the image files in the folder\n",
    "image_folder = '/home/noahr/repos/personal_projects/img_to_svg/Images'\n",
    "image_files = [os.path.join(image_folder, f) for f in os.listdir(image_folder) if f.endswith('.jpg')]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_l_0b3195.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://download.pytorch.org/models/retinanet_resnet50_fpn_coco-eeacb38b.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "from segment_anything import sam_model_registry, SamPredictor\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# sam_checkpoint = \"sam_vit_h_4b8939.pth\"\n",
    "# model_type = \"vit_h\"\n",
    "\n",
    "sam_checkpoint = \"sam_vit_l_0b3195.pth\"\n",
    "model_type = \"vit_l\"\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "sam.to(device=device)\n",
    "\n",
    "predictor = SamPredictor(sam)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define paths for folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to connect to the remote Jupyter Server 'http://0.0.0.0:2326/'. Verify the server is running and reachable. (request to http://0.0.0.0:2326/notebook/hub/api failed, reason: connect ECONNREFUSED 0.0.0.0:2326)."
     ]
    }
   ],
   "source": [
    "# Define the paths to the images and masks folders (Change these to other folders in your machine if you prefer that)\n",
    "import os\n",
    "\n",
    "# For Local\n",
    "images_path = os.path.join(os.getcwd(), 'Images')\n",
    "masks_path = os.path.join(os.getcwd(), 'masks')\n",
    "cutouts_path = os.path.join(os.getcwd(), 'cutouts')\n",
    "svg_path = os.path.join(os.getcwd(), 'svg')\n",
    "video_images_path = os.path.join(os.getcwd(), 'video_images')\n",
    "\n",
    "\n",
    "# For Beam\n",
    "# Define the paths to the images and masks folders (Change these to other folders in your machine if you prefer that)\n",
    "# images_path = os.path.join('uploaded_images/Images')\n",
    "# masks_path = os.path.join('masks')\n",
    "# cutouts_path = os.path.join('cutouts')\n",
    "# svg_path = os.path.join('svg')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate coco masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n-cls.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "\n",
    "model = YOLO('yolov8n.pt')\n",
    "results = model('Images/00100sPORTRAIT_00100_BURST20221127125031811_COVER.jpg')\n",
    "img = cv2.imread('Images/00100sPORTRAIT_00100_BURST20221127125031811_COVER.jpg')\n",
    "for result in results:\n",
    "    boxes = result.boxes.cpu().numpy()\n",
    "    for i, box in enumerate(boxes):\n",
    "        r = box.xyxy[0].astype(int)\n",
    "        print(r)\n",
    "        crop = img[r[1]:r[3], r[0]:r[2]]\n",
    "        cv2.imwrite(str(i) + \".jpg\", crop)\n",
    "        print(\"names: \",result.names[int(box.cls[0])])\n",
    "        print(str(i) + \".jpg\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mutli-threaded masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from pycocotools import mask as maskUtils\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from queue import Queue\n",
    "\n",
    "# Load the YOLOv5 model from torchub\n",
    "model = YOLO('yolov8n.pt')\n",
    "# Define the class you want to detect\n",
    "class_to_detect = 'person'\n",
    "\n",
    "# Define the path to the log file\n",
    "log_file = os.path.join(os.getcwd(), 'yolo_mask.log')\n",
    "\n",
    "# Define the number of workers to use\n",
    "num_workers = 4\n",
    "\n",
    "# Define a function to process a single image\n",
    "def process_image(filename):\n",
    "    # Check if a mask file already exists for this image\n",
    "    mask_number = 0\n",
    "    mask_filename = os.path.splitext(filename)[0] + '_mask_{}.json'.format(mask_number)\n",
    "    while os.path.exists(os.path.join(masks_path, mask_filename)):\n",
    "        mask_number += 1\n",
    "        mask_filename = os.path.splitext(filename)[0] + '_mask_{}.json'.format(mask_number)\n",
    "    if mask_number > 0:\n",
    "        return\n",
    "    \n",
    "    # Load the image\n",
    "    image = cv2.imread(os.path.join(images_path, filename))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    # Redirect the YOLO model output to the log file\n",
    "    sys.stdout = open(log_file, 'w')\n",
    "    \n",
    "    # Run the model on the image\n",
    "    results = model(image)\n",
    "    predictor.set_image(image)\n",
    "    \n",
    "    for result in results:\n",
    "        boxes = result.boxes.cpu().numpy()\n",
    "        for i, box in enumerate(boxes):\n",
    "            if result.names[int(box.cls[0])] == class_to_detect:\n",
    "                masks, _, _ = predictor.predict(\n",
    "                    point_coords=None,\n",
    "                    point_labels=None,\n",
    "                    box=box.xyxy[0].astype(int),\n",
    "                    multimask_output=True,\n",
    "                )\n",
    "                for i, mask in enumerate(masks):\n",
    "                    # Convert the mask numpy array to a binary mask\n",
    "                    mask_binary = np.zeros((mask.shape[0], mask.shape[1]), dtype=np.uint8)\n",
    "                    mask_binary[mask > 0] = 1\n",
    "                        \n",
    "                    # Convert the binary mask to a COCO RLE format\n",
    "                    mask_rle = maskUtils.encode(np.asfortranarray(mask_binary))\n",
    "                        \n",
    "                    # Extract the counts key from the mask RLE dictionary\n",
    "                    counts = mask_rle['counts']\n",
    "                        \n",
    "                    # Create a new dictionary with the required keys for COCO RLE format\n",
    "                    mask_coco_rle = {\n",
    "                        'size': [mask.shape[0], mask.shape[1]],\n",
    "                        'counts': counts.decode('utf-8'),\n",
    "                    }\n",
    "                        \n",
    "                    # Save the mask COCO RLE to a file\n",
    "                    mask_filename = os.path.splitext(filename)[0] + '_mask_{}.json'.format(i)\n",
    "                    with open(os.path.join(masks_path, mask_filename), 'w') as f:\n",
    "                        json.dump(mask_coco_rle, f)\n",
    "\n",
    "# Get a list of all the image filenames\n",
    "image_filenames = os.listdir(images_path)\n",
    "print(\"FileName: \", image_filenames)\n",
    "# Create a thread-safe queue to hold the image filenames\n",
    "queue = Queue()\n",
    "for filename in image_filenames:\n",
    "    queue.put(filename)\n",
    "\n",
    "# Define a function to process images from the queue\n",
    "def process_queue():\n",
    "    while not queue.empty():\n",
    "        filename = queue.get()\n",
    "        process_image(filename)\n",
    "        queue.task_done()\n",
    "\n",
    "# Create a thread pool with the specified number of workers\n",
    "with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "    # Submit each image filename to the thread pool\n",
    "    futures = [executor.submit(process_queue) for _ in range(num_workers)]\n",
    "\n",
    "    # Wait for all the futures to complete\n",
    "    for future in as_completed(futures):\n",
    "        # Print any exceptions that occurred during processing\n",
    "        if future.exception() is not None:\n",
    "            print(future.exception())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal single-file masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the YOLOv5 model from torchub\n",
    "model = YOLO('yolov8n.pt')\n",
    "# Define the class you want to detect\n",
    "class_to_detect = 'person'\n",
    "\n",
    "# Loop through all the files in the images folder\n",
    "for filename in os.listdir(images_path):\n",
    "    # Check if a mask file already exists for this image\n",
    "    mask_number = 0\n",
    "    mask_filename = os.path.splitext(filename)[0] + '_mask_{}.json'.format(mask_number)\n",
    "    while os.path.exists(os.path.join(masks_path, mask_filename)):\n",
    "        mask_number += 1\n",
    "        mask_filename = os.path.splitext(filename)[0] + '_mask_{}.json'.format(mask_number)\n",
    "    if mask_number > 0:\n",
    "        continue\n",
    "    \n",
    "    # Load the image\n",
    "    image = cv2.imread(os.path.join(images_path, filename))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Run the model on the image\n",
    "    results = model(image)\n",
    "    predictor.set_image(image)\n",
    "    \n",
    "    for result in results:\n",
    "        boxes = result.boxes.cpu().numpy()\n",
    "        for i, box in enumerate(boxes):\n",
    "            # print(\"names: \",result.names[int(box.cls[0])])\n",
    "            if result.names[int(box.cls[0])] == class_to_detect:\n",
    "                masks, _, _ = predictor.predict(\n",
    "                    point_coords=None,\n",
    "                    point_labels=None,\n",
    "                    box=box.xyxy[0].astype(int),\n",
    "                    multimask_output=True,\n",
    "                )\n",
    "                for i, mask in enumerate(masks):\n",
    "                    # Convert the mask numpy array to a binary mask\n",
    "                    mask_binary = np.zeros((mask.shape[0], mask.shape[1]), dtype=np.uint8)\n",
    "                    mask_binary[mask > 0] = 1\n",
    "                        \n",
    "                    # Convert the binary mask to a COCO RLE format\n",
    "                    mask_rle = maskUtils.encode(np.asfortranarray(mask_binary))\n",
    "                        \n",
    "                    # Extract the counts key from the mask RLE dictionary\n",
    "                    counts = mask_rle['counts']\n",
    "                        \n",
    "                    # Create a new dictionary with the required keys for COCO RLE format\n",
    "                    mask_coco_rle = {\n",
    "                        'size': [mask.shape[0], mask.shape[1]],\n",
    "                        'counts': counts.decode('utf-8'),\n",
    "                    }\n",
    "                        \n",
    "                    # Save the mask COCO RLE to a file\n",
    "                    mask_filename = os.path.splitext(filename)[0] + '_mask_{}.json'.format(i)\n",
    "                    with open(os.path.join(masks_path, mask_filename), 'w') as f:\n",
    "                        json.dump(mask_coco_rle, f)\n",
    "                "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create cutouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from pycocotools import mask as maskUtils\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from queue import Queue\n",
    "\n",
    "# Loop through all the files in the images folder\n",
    "for filename in os.listdir(images_path):\n",
    "    # Check if there are any mask files in the folder\n",
    "    if not os.listdir(masks_path):\n",
    "        exit()\n",
    "    \n",
    "    # Load the image\n",
    "    image = cv2.imread(os.path.join(images_path, filename))\n",
    "    \n",
    "    # Load the corresponding mask\n",
    "    mask_number = 0\n",
    "    cutout_number = 0\n",
    "    mask_filename = os.path.splitext(filename)[0] + '_mask_{}.json'.format(mask_number)\n",
    "    while os.path.exists(os.path.join(masks_path, mask_filename)):\n",
    "        with open(os.path.join(masks_path, mask_filename), 'r') as f:\n",
    "            rle_dict = json.load(f)\n",
    "        size = rle_dict['size']\n",
    "        counts = rle_dict['counts']\n",
    "        mask_decoded = maskUtils.decode({'size': size, 'counts': counts})\n",
    "        mask_binary = np.zeros((size[0], size[1]), dtype=np.uint8)\n",
    "        mask_binary[mask_decoded > 0] = 1\n",
    "\n",
    "        # Resize the mask to match the shape of the image\n",
    "        mask_resized = cv2.resize(mask_decoded, (image.shape[1], image.shape[0]))\n",
    "\n",
    "        # Extract the cutout from the image using the mask\n",
    "        cutout = image * mask_resized[..., np.newaxis]\n",
    "\n",
    "        # Create an alpha channel for the cutout image\n",
    "        alpha = np.zeros(cutout.shape[:2], dtype=np.uint8)\n",
    "        alpha[mask_resized > 0] = 255\n",
    "        cutout = cv2.merge((cutout, alpha))\n",
    "\n",
    "        # Crop the cutout image to the bounding rectangle\n",
    "        x, y, w, h = cv2.boundingRect(mask_resized)\n",
    "        cutout = cutout[y:y+h, x:x+w]\n",
    "\n",
    "        # Save the cutout to the cutouts folder\n",
    "        cutout_filename = os.path.splitext(filename)[0] + '_cutout_{}.png'.format(cutout_number)\n",
    "        if os.path.exists(os.path.join(cutouts_path, cutout_filename)):\n",
    "            os.remove(os.path.join(cutouts_path, cutout_filename))\n",
    "        cv2.imwrite(os.path.join(cutouts_path, cutout_filename), cutout)\n",
    "        \n",
    "        # Delete the mask file\n",
    "        os.remove(os.path.join(masks_path, mask_filename))\n",
    "        \n",
    "        # Increment the mask and cutout numbers\n",
    "        mask_number += 1\n",
    "        cutout_number += 1\n",
    "        mask_filename = os.path.splitext(filename)[0] + '_mask_{}.json'.format(mask_number)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-threaded cutouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from pycocotools import mask as maskUtils\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from queue import Queue\n",
    "\n",
    "# Define the number of workers to use\n",
    "num_workers = 10\n",
    "\n",
    "# Define a function to process a single image\n",
    "def process_image(filename):\n",
    "    # Check if there are any mask files in the folder\n",
    "    if not os.listdir(masks_path):\n",
    "        return\n",
    "    \n",
    "    # Load the image\n",
    "    image = cv2.imread(os.path.join(images_path, filename))\n",
    "    \n",
    "    # Load the corresponding mask\n",
    "    mask_number = 0\n",
    "    cutout_number = 0\n",
    "    mask_filename = os.path.splitext(filename)[0] + '_mask_{}.json'.format(mask_number)\n",
    "    while os.path.exists(os.path.join(masks_path, mask_filename)):\n",
    "        with open(os.path.join(masks_path, mask_filename), 'r') as f:\n",
    "            rle_dict = json.load(f)\n",
    "        size = rle_dict['size']\n",
    "        counts = rle_dict['counts']\n",
    "        mask_decoded = maskUtils.decode({'size': size, 'counts': counts})\n",
    "        mask_binary = np.zeros((size[0], size[1]), dtype=np.uint8)\n",
    "        mask_binary[mask_decoded > 0] = 1\n",
    "\n",
    "        # Resize the mask to match the shape of the image\n",
    "        mask_resized = cv2.resize(mask_decoded, (image.shape[1], image.shape[0]))\n",
    "\n",
    "        # Extract the cutout from the image using the mask\n",
    "        cutout = image * mask_resized[..., np.newaxis]\n",
    "\n",
    "        # Create an alpha channel for the cutout image\n",
    "        alpha = np.zeros(cutout.shape[:2], dtype=np.uint8)\n",
    "        alpha[mask_resized > 0] = 255\n",
    "        cutout = cv2.merge((cutout, alpha))\n",
    "\n",
    "        # Crop the cutout image to the bounding rectangle\n",
    "        x, y, w, h = cv2.boundingRect(mask_resized)\n",
    "        cutout = cutout[y:y+h, x:x+w]\n",
    "\n",
    "        # Save the cutout to the cutouts folder\n",
    "        cutout_filename = os.path.splitext(filename)[0] + '_cutout_{}.png'.format(cutout_number)\n",
    "        if os.path.exists(os.path.join(cutouts_path, cutout_filename)):\n",
    "            os.remove(os.path.join(cutouts_path, cutout_filename))\n",
    "        cv2.imwrite(os.path.join(cutouts_path, cutout_filename), cutout)\n",
    "        \n",
    "        # Delete the mask file\n",
    "        os.remove(os.path.join(masks_path, mask_filename))\n",
    "        \n",
    "        # Increment the mask and cutout numbers\n",
    "        mask_number += 1\n",
    "        cutout_number += 1\n",
    "        mask_filename = os.path.splitext(filename)[0] + '_mask_{}.json'.format(mask_number)\n",
    "\n",
    "# Get a list of all the image filenames\n",
    "image_filenames = os.listdir(images_path)\n",
    "\n",
    "# Create a thread-safe queue to hold the image filenames\n",
    "queue = Queue()\n",
    "for filename in image_filenames:\n",
    "    queue.put(filename)\n",
    "\n",
    "# Define a function to process images from the queue\n",
    "def process_queue():\n",
    "    while not queue.empty():\n",
    "        filename = queue.get()\n",
    "        process_image(filename)\n",
    "        queue.task_done()\n",
    "\n",
    "# Create a thread pool with the specified number of workers\n",
    "with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "    # Submit each image filename to the thread pool\n",
    "    futures = [executor.submit(process_queue) for _ in range(num_workers)]\n",
    "\n",
    "    # Wait for all the futures to complete\n",
    "    for future in as_completed(futures):\n",
    "        # Print any exceptions that occurred during processing\n",
    "        if future.exception() is not None:\n",
    "            print(future.exception())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make svg from png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "# Define the paths to the cutouts and output folders\n",
    "cutouts_path = '/home/noahr/repos/personal_projects/img_to_svg/cutouts'\n",
    "output_path = '/home/noahr/repos/personal_projects/img_to_svg/svg'\n",
    "\n",
    "# Loop through all the files in the cutouts folder\n",
    "for filename in os.listdir(cutouts_path):\n",
    "    if filename.endswith('.png'):\n",
    "        # Define the paths to the input and output files\n",
    "        png_path = os.path.join(cutouts_path, filename)\n",
    "        pbm_path = os.path.join(cutouts_path, os.path.splitext(filename)[0] + '.pbm')\n",
    "        svg_filename = os.path.splitext(filename)[0] + '.svg'\n",
    "        svg_path = os.path.join(output_path, svg_filename)\n",
    "\n",
    "        # Convert the PNG to PBM format\n",
    "        with Image.open(png_path) as im:\n",
    "            im.convert('1').save(pbm_path)\n",
    "\n",
    "        # Call potrace to convert the PBM to SVG\n",
    "        subprocess.call(['potrace', '-s', pbm_path, '-o', svg_path])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get frames from video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install setuptools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install ez_setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install moviepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create detector object\n",
    "detector = ObjectDetection()\n",
    "\n",
    "# Set model path\n",
    "model_path = \"/home/noahr/repos/personal_projects/img_to_svg/retinanet_resnet50_fpn_coco-eeacb38b.pth\"\n",
    "detector.setModelTypeAsRetinaNet()\n",
    "detector.setModelPath(model_path)\n",
    "detector.loadModel()\n",
    "\n",
    "# Loop through all files in input folder\n",
    "for filename in os.listdir(images_path):\n",
    "    # Check if file is an mp4 video\n",
    "    if filename.endswith(\".mp4\"):\n",
    "        # Set video path\n",
    "        video_path = os.path.join(images_path, filename)\n",
    "        \n",
    "        # Extract frames from video\n",
    "        video_frames_path = os.path.join(video_images_path, filename)\n",
    "        os.makedirs(video_frames_path, exist_ok=True)\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        frame_count = 0\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame_path = os.path.join(video_frames_path, f\"frame_{frame_count}.jpg\")\n",
    "            cv2.imwrite(frame_path, frame)\n",
    "            frame_count += 1\n",
    "        \n",
    "        # Loop through frames and detect objects\n",
    "        for frame in os.listdir(video_frames_path):\n",
    "            frame_path = os.path.join(video_frames_path, frame)\n",
    "            detections = detector.detectObjectsFromImage(input_image=frame_path, output_image_path=os.path.join(video_images_path, \"frame.jpg\"), minimum_percentage_probability=80)\n",
    "            \n",
    "            # Loop through detections and save images with people\n",
    "            for detection in detections:\n",
    "                if detection[\"name\"] == \"person\":\n",
    "                    image_path = os.path.join(video_images_path, f\"{filename}_{detection['box_points'][0]}_{detection['box_points'][1]}.jpg\")\n",
    "                    frame = cv2.imread(frame_path)\n",
    "                    cv2.imwrite(image_path, frame)\n",
    "\n",
    "# Delete all images and folders inside video_images_path\n",
    "for file in os.listdir(video_images_path):\n",
    "    file_path = os.path.join(video_images_path, file)\n",
    "    if os.path.isfile(file_path):\n",
    "        os.remove(file_path)\n",
    "    elif os.path.isdir(file_path):\n",
    "        os.rmdir(file_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For WSL2 Remove all zone.identifier tags after C&P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through files in folder\n",
    "for filename in os.listdir(images_path):\n",
    "    # Check if file has the zone.identifier extension\n",
    "    if filename.endswith(\".zone.identifier\"):\n",
    "        # Set file path\n",
    "        file_path = os.path.join(images_path, filename)\n",
    "        \n",
    "        # Delete file\n",
    "        os.remove(file_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make svg from png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# Loop through all the files in the cutouts folder\n",
    "for filename in os.listdir(cutouts_path):\n",
    "    if filename.endswith('.png'):\n",
    "        # Define the paths to the input and output files\n",
    "        png_path = os.path.join(cutouts_path, filename)\n",
    "        pbm_path = os.path.join(cutouts_path, os.path.splitext(filename)[0] + '.pbm')\n",
    "        svg_filename = os.path.splitext(filename)[0] + '.svg'\n",
    "        svg_path = os.path.join(svg_path, svg_filename)\n",
    "\n",
    "        # Convert the PNG to PBM format\n",
    "        with Image.open(png_path) as im:\n",
    "            im.convert('1').save(pbm_path)\n",
    "\n",
    "        # Call potrace to convert the PBM to SVG\n",
    "        subprocess.call(['potrace', '-s', pbm_path, '-o', svg_path])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
